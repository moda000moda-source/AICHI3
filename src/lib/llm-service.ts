/**
 * LLM Service Layer for AI Assistant
 * 
 * Provides integration with various LLM providers including:
 * - iFlytek Spark (ç§‘å¤§è®¯é£æ˜Ÿç«å¤§æ¨¡å‹)
 * - OpenAI API compatible services
 * - Custom endpoints
 * 
 * For iFlytek Spark-13B integration:
 * Repository: https://gitee.com/iflytekopensource/iFlytekSpark-13B
 * Documentation: https://www.xfyun.cn/doc/spark/Web.html
 */

import type { 
  LLMModelConfig, 
  LLMProvider, 
  LLMRequest, 
  LLMResponse, 
  LLMRequestMessage,
  IFlytekSparkConfig 
} from './types';

// Default model configurations
export const DEFAULT_LLM_CONFIGS: LLMModelConfig[] = [
  {
    id: 'mock',
    provider: 'mock',
    name: 'æ¨¡æ‹Ÿæ¨¡å¼',
    description: 'ä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿå“åº”ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰',
    enabled: true,
    maxTokens: 2048,
    temperature: 0.7,
  },
  {
    id: 'iflytek-spark-13b',
    provider: 'iflytek-spark',
    name: 'è®¯é£æ˜Ÿç« 13B',
    description: 'åŸºäºiFlytekSpark-13Bçš„å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œé€‚åˆäºŒæ¬¡å¼€å‘å®šåˆ¶',
    modelVersion: '13B',
    maxTokens: 4096,
    temperature: 0.5,
    enabled: false,
  },
  {
    id: 'iflytek-spark-v3',
    provider: 'iflytek-spark',
    name: 'è®¯é£æ˜Ÿç« V3.5',
    description: 'è®¯é£æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹V3.5ç‰ˆæœ¬ï¼Œæ”¯æŒè”ç½‘æœç´¢',
    modelVersion: 'v3.5',
    maxTokens: 8192,
    temperature: 0.5,
    enabled: false,
  },
  {
    id: 'custom-model',
    provider: 'custom',
    name: 'è‡ªå®šä¹‰æ¨¡å‹',
    description: 'è¿æ¥è‡ªæ‰˜ç®¡çš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹æœåŠ¡',
    maxTokens: 4096,
    temperature: 0.7,
    enabled: false,
  },
];

// iFlytek Spark WebSocket URL mappings (for reference when implementing backend)
// eslint-disable-next-line @typescript-eslint/no-unused-vars
const SPARK_WS_URLS: Record<string, string> = {
  'v1.5': 'wss://spark-api.xf-yun.com/v1.1/chat',
  'v2.0': 'wss://spark-api.xf-yun.com/v2.1/chat',
  'v3.0': 'wss://spark-api.xf-yun.com/v3.1/chat',
  'v3.5': 'wss://spark-api.xf-yun.com/v3.5/chat',
  'v4.0': 'wss://spark-api.xf-yun.com/v4.0/chat',
  '13B': 'wss://spark-api.xf-yun.com/v1.1/chat', // Uses v1 API for local deployment
};

// iFlytek Spark domain mappings (for reference when implementing backend)
// eslint-disable-next-line @typescript-eslint/no-unused-vars
const SPARK_DOMAINS: Record<string, string> = {
  'v1.5': 'general',
  'v2.0': 'generalv2',
  'v3.0': 'generalv3',
  'v3.5': 'generalv3.5',
  'v4.0': 'generalv4.0',
  '13B': 'general',
};

/**
 * Get the WebSocket URL for iFlytek Spark API
 * Note: Authentication should be done server-side to protect API secrets
 * TODO: Implement full authentication flow in backend service
 */
export function getSparkWebSocketUrl(config: IFlytekSparkConfig): string {
  // In production, authentication should be handled by a backend service
  // that generates the proper HMAC-SHA256 signature
  return config.sparkUrl;
}

/**
 * Format messages for iFlytek Spark API
 * This helper is provided for backend service implementation
 */
export function formatMessagesForSpark(messages: LLMRequestMessage[]): object {
  return {
    text: messages.map(msg => ({
      role: msg.role,
      content: msg.content,
    })),
  };
}

/**
 * LLM Service class for handling AI model requests
 */
export class LLMService {
  private config: LLMModelConfig;
  private systemPrompt: string;

  constructor(config: LLMModelConfig) {
    this.config = config;
    this.systemPrompt = `ä½ æ˜¯ OmniCore æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šçº§åŠ å¯†èµ„äº§ç®¡ç†å¹³å°AIåŠ©æ‰‹ã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›åŒ…æ‹¬:
1. é’±åŒ…ç®¡ç† - å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢ä½™é¢ã€åˆ›å»ºé’±åŒ…ã€ç®¡ç†èµ„äº§
2. äº¤æ˜“å¤„ç† - ååŠ©å‘èµ·ã€å®¡æ ¸å’Œç­¾ç½²äº¤æ˜“
3. DeFiç­–ç•¥ - æä¾›æ”¶ç›Šä¼˜åŒ–å»ºè®®å’Œé£é™©åˆ†æ
4. é£é™©è¯„ä¼° - å®æ—¶è¯„ä¼°äº¤æ˜“å’Œåœ°å€é£é™©
5. æ”¯ä»˜ç½‘å…³ - å¤„ç†å¤šæ¸ é“æ”¯ä»˜è¯·æ±‚

è¯·ç”¨ä¸“ä¸šã€å‹å¥½çš„è¯­æ°”å›å¤ç”¨æˆ·ã€‚å¦‚æœæ¶‰åŠæ•æ„Ÿæ“ä½œï¼Œè¯·æé†’ç”¨æˆ·è¿›è¡ŒäºŒæ¬¡ç¡®è®¤ã€‚
å¯¹äºå¤æ‚é—®é¢˜ï¼Œè¯·åˆ†æ­¥éª¤æ¸…æ™°åœ°è§£é‡Šã€‚`;
  }

  /**
   * Send a chat completion request to the configured LLM
   */
  async chat(userMessage: string, conversationHistory: LLMRequestMessage[] = []): Promise<LLMResponse> {
    const messages: LLMRequestMessage[] = [
      { role: 'system', content: this.systemPrompt },
      ...conversationHistory,
      { role: 'user', content: userMessage },
    ];

    const request: LLMRequest = {
      messages,
      maxTokens: this.config.maxTokens,
      temperature: this.config.temperature,
    };

    switch (this.config.provider) {
      case 'mock':
        return this.mockChat(request);
      case 'iflytek-spark':
        return this.iflytekSparkChat(request);
      case 'custom':
        return this.customChat(request);
      default:
        return this.mockChat(request);
    }
  }

  /**
   * Mock chat implementation for testing
   */
  private async mockChat(request: LLMRequest): Promise<LLMResponse> {
    const userMessage = request.messages[request.messages.length - 1].content;
    const response = this.generateMockResponse(userMessage);
    
    // Simulate network delay
    await new Promise(resolve => setTimeout(resolve, 800 + Math.random() * 700));

    return {
      success: true,
      content: response,
      usage: {
        promptTokens: Math.floor(userMessage.length / 4),
        completionTokens: Math.floor(response.length / 4),
        totalTokens: Math.floor((userMessage.length + response.length) / 4),
      },
    };
  }

  /**
   * iFlytek Spark chat implementation
   * Note: WebSocket connection should be handled by backend for security
   */
  private async iflytekSparkChat(request: LLMRequest): Promise<LLMResponse> {
    // Check if configuration is complete
    if (!this.config.apiKey || !this.config.appId || !this.config.apiSecret) {
      return {
        success: false,
        error: 'è¯·å…ˆé…ç½®è®¯é£æ˜Ÿç«APIå¯†é’¥ã€‚é…ç½®è·¯å¾„: AIåŠ©æ‰‹ > èƒ½åŠ› > æ¨¡å‹è®¾ç½®',
      };
    }

    try {
      // In a real implementation, this would connect to a backend service
      // that handles the WebSocket connection to iFlytek Spark API
      // 
      // For iFlytek Spark-13B local deployment:
      // 1. Clone: git clone https://gitee.com/iflytekopensource/iFlytekSpark-13B.git
      // 2. Follow the deployment guide in the repository
      // 3. Configure your local endpoint URL
      
      const endpoint = this.config.apiEndpoint || '/api/llm/spark';
      
      // This would call your backend API
      const response = await fetch(endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-App-Id': this.config.appId,
        },
        body: JSON.stringify({
          model: this.config.modelVersion,
          messages: request.messages.map(m => ({
            role: m.role,
            content: m.content,
          })),
          max_tokens: request.maxTokens,
          temperature: request.temperature,
        }),
      });

      if (!response.ok) {
        throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status}`);
      }

      const data = await response.json();
      
      return {
        success: true,
        content: data.choices?.[0]?.message?.content || data.content || '',
        usage: data.usage,
      };
    } catch (error) {
      // Fallback to mock if API fails
      console.error('iFlytek Spark API error:', error);
      return {
        success: false,
        error: `è®¯é£æ˜Ÿç«APIè°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}ã€‚å·²åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼ã€‚`,
      };
    }
  }

  /**
   * Custom endpoint chat implementation
   */
  private async customChat(request: LLMRequest): Promise<LLMResponse> {
    if (!this.config.apiEndpoint) {
      return {
        success: false,
        error: 'è¯·é…ç½®è‡ªå®šä¹‰æ¨¡å‹APIç«¯ç‚¹',
      };
    }

    try {
      const response = await fetch(this.config.apiEndpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(this.config.apiKey && { 'Authorization': `Bearer ${this.config.apiKey}` }),
        },
        body: JSON.stringify({
          messages: request.messages,
          max_tokens: request.maxTokens,
          temperature: request.temperature,
        }),
      });

      if (!response.ok) {
        throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status}`);
      }

      const data = await response.json();
      
      return {
        success: true,
        content: data.choices?.[0]?.message?.content || data.content || '',
        usage: data.usage,
      };
    } catch (error) {
      return {
        success: false,
        error: `è‡ªå®šä¹‰APIè°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
      };
    }
  }

  /**
   * Generate mock response based on user input
   */
  private generateMockResponse(input: string): string {
    const lowerInput = input.toLowerCase();
    
    if (lowerInput.includes('é’±åŒ…') || lowerInput.includes('ä½™é¢') || lowerInput.includes('wallet') || lowerInput.includes('balance')) {
      return 'æˆ‘å·²ç»æ£€æŸ¥äº†æ‚¨çš„é’±åŒ…çŠ¶æ€ã€‚æ‚¨ç›®å‰æœ‰:\n\nğŸ’° **æ€»èµ„äº§**: $231,690.75\n\nä¸»è¦é’±åŒ…:\n- Treasury Vault: $125,432 (Ethereum)\n- Operating Account: $23,234 (Polygon)\n- DeFi Strategy: $8,024 (Arbitrum)\n\néœ€è¦æˆ‘æ‰§è¡Œä»€ä¹ˆæ“ä½œå—ï¼Ÿ';
    }
    
    if (lowerInput.includes('äº¤æ˜“') || lowerInput.includes('è½¬è´¦') || lowerInput.includes('transaction') || lowerInput.includes('transfer')) {
      return 'æˆ‘å¯ä»¥å¸®æ‚¨åˆ›å»ºæ–°äº¤æ˜“ã€‚è¯·æä¾›ä»¥ä¸‹ä¿¡æ¯:\n\n1. å‘é€æ–¹é’±åŒ…\n2. æ¥æ”¶åœ°å€\n3. é‡‘é¢å’Œä»£å¸\n4. äº¤æ˜“æè¿°\n\næˆ–è€…æ‚¨å¯ä»¥è¯´ "ä»Treasury Vaultè½¬è´¦5000 USDCåˆ°ä¾›åº”å•†"ï¼Œæˆ‘ä¼šè‡ªåŠ¨è§£æã€‚';
    }
    
    if (lowerInput.includes('é£é™©') || lowerInput.includes('åˆ†æ') || lowerInput.includes('risk') || lowerInput.includes('analysis')) {
      return 'ğŸ” **é£é™©åˆ†ææŠ¥å‘Š**\n\nå½“å‰å¾…å¤„ç†äº¤æ˜“é£é™©:\n\nâš ï¸ **é«˜é£é™©** - tx-3 (Operating Account)\n- å¤§é¢è½¬è´¦: 25,000 USDT\n- é¦–æ¬¡æ”¶æ¬¾åœ°å€\n- å»ºè®®: éªŒè¯æ”¶æ¬¾æ–¹èº«ä»½\n\nâœ… **ä½é£é™©** - tx-1 (Treasury Vault)\n- å·²çŸ¥æ”¶æ¬¾æ–¹\n- å¸¸è§„äº¤æ˜“æ¨¡å¼\n\néœ€è¦æˆ‘æä¾›æ›´è¯¦ç»†çš„åˆ†æå—ï¼Ÿ';
    }
    
    if (lowerInput.includes('defi') || lowerInput.includes('ç­–ç•¥') || lowerInput.includes('æ”¶ç›Š')) {
      return 'ğŸ“Š **DeFi ç­–ç•¥å»ºè®®**\n\nåŸºäºæ‚¨çš„é£é™©åå¥½ï¼Œæ¨è:\n\n1. **ç¨³å®šå¸å€Ÿè´·** (Aave V3)\n   - APY: 5.2%\n   - é£é™©: ä½\n\n2. **ETH è´¨æŠ¼** (Lido)\n   - APY: 3.8%\n   - é£é™©: ä½\n\n3. **æµåŠ¨æ€§æŒ–çŸ¿** (Uniswap V3)\n   - APY: 12.5%\n   - é£é™©: ä¸­\n\néœ€è¦æˆ‘å¸®æ‚¨é…ç½®è‡ªåŠ¨æŠ•èµ„ç­–ç•¥å—ï¼Ÿ';
    }

    if (lowerInput.includes('æ¨¡å‹') || lowerInput.includes('é…ç½®') || lowerInput.includes('spark') || lowerInput.includes('è®¯é£')) {
      return 'ğŸ¤– **AIæ¨¡å‹é…ç½®è¯´æ˜**\n\nå½“å‰æ”¯æŒä»¥ä¸‹æ¨¡å‹:\n\n1. **è®¯é£æ˜Ÿç« 13B** (å¼€æºç‰ˆ)\n   - å¯æœ¬åœ°éƒ¨ç½²å’ŒäºŒæ¬¡å¼€å‘\n   - ä»“åº“: gitee.com/iflytekopensource/iFlytekSpark-13B\n\n2. **è®¯é£æ˜Ÿç« V3.5** (äº‘ç«¯API)\n   - éœ€è¦APIå¯†é’¥\n\n3. **è‡ªå®šä¹‰æ¨¡å‹**\n   - æ”¯æŒOpenAIå…¼å®¹API\n\nè¯·åœ¨"èƒ½åŠ›"æ ‡ç­¾é¡µä¸­é…ç½®æ‚¨çš„æ¨¡å‹ã€‚';
    }
    
    return 'æ„Ÿè°¢æ‚¨çš„æé—®ï¼æˆ‘æ˜¯ OmniCore æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨:\n\nâ€¢ ğŸ“Š æŸ¥è¯¢å’Œç®¡ç†é’±åŒ…\nâ€¢ ğŸ’¸ åˆ›å»ºå’Œç­¾ç½²äº¤æ˜“\nâ€¢ ğŸ” åˆ†æäº¤æ˜“é£é™©\nâ€¢ ğŸ“ˆ ç®¡ç† DeFi ç­–ç•¥\nâ€¢ âš™ï¸ é…ç½®å¹³å°è®¾ç½®\nâ€¢ ğŸ¤– é…ç½®AIæ¨¡å‹ï¼ˆæ”¯æŒè®¯é£æ˜Ÿç«13Bç­‰ï¼‰\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ';
  }

  /**
   * Update service configuration
   */
  updateConfig(config: Partial<LLMModelConfig>): void {
    this.config = { ...this.config, ...config };
  }

  /**
   * Get current configuration
   */
  getConfig(): LLMModelConfig {
    return { ...this.config };
  }
}

/**
 * Create LLM service instance with default configuration
 */
export function createLLMService(config?: Partial<LLMModelConfig>): LLMService {
  const defaultConfig = DEFAULT_LLM_CONFIGS[0]; // Mock by default
  return new LLMService({ ...defaultConfig, ...config });
}

/**
 * Get iFlytek Spark setup instructions
 */
export function getIFlytekSparkSetupGuide(): string {
  return `# è®¯é£æ˜Ÿç«13BäºŒæ¬¡å¼€å‘æŒ‡å—

## æ¦‚è¿°
iFlytekSpark-13Bæ˜¯ç§‘å¤§è®¯é£å¼€æºçš„130äº¿å‚æ•°å¤§è¯­è¨€æ¨¡å‹ï¼Œé€‚åˆä¼ä¸šè¿›è¡Œå®šåˆ¶åŒ–å¼€å‘ã€‚

## è·å–æ¨¡å‹

### æ–¹å¼ä¸€ï¼šå…‹éš†å¼€æºä»“åº“
\`\`\`bash
git clone https://gitee.com/iflytekopensource/iFlytekSpark-13B.git
cd iFlytekSpark-13B
\`\`\`

### æ–¹å¼äºŒï¼šä½¿ç”¨äº‘ç«¯API
1. è®¿é—® https://www.xfyun.cn/
2. æ³¨å†Œå¼€å‘è€…è´¦å·
3. åˆ›å»ºåº”ç”¨è·å– APP_ID, API_KEY, API_SECRET

## æœ¬åœ°éƒ¨ç½²è¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- GPU: è‡³å°‘24GBæ˜¾å­˜ (æ¨èA100 40GB/80GB)
- RAM: è‡³å°‘64GB
- å­˜å‚¨: è‡³å°‘50GB SSD

### è½¯ä»¶è¦æ±‚
- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+
- transformers 4.30+

## é…ç½®æ­¥éª¤

1. **å®‰è£…ä¾èµ–**
\`\`\`bash
pip install torch transformers accelerate
\`\`\`

2. **ä¸‹è½½æ¨¡å‹æƒé‡**
æŒ‰ç…§ä»“åº“READMEæŒ‡å¼•ä¸‹è½½æ¨¡å‹æ–‡ä»¶

3. **å¯åŠ¨æ¨ç†æœåŠ¡**
\`\`\`python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("./iFlytekSpark-13B")
tokenizer = AutoTokenizer.from_pretrained("./iFlytekSpark-13B")
\`\`\`

4. **åœ¨OmniCoreä¸­é…ç½®**
- è¿›å…¥ AIåŠ©æ‰‹ > èƒ½åŠ› > æ¨¡å‹è®¾ç½®
- é€‰æ‹©"è®¯é£æ˜Ÿç« 13B"
- é…ç½®æœ¬åœ°APIç«¯ç‚¹

## äºŒæ¬¡å¼€å‘åœºæ™¯

1. **é‡‘èçŸ¥è¯†å¢å¼º** - ä½¿ç”¨é¢†åŸŸæ•°æ®å¾®è°ƒ
2. **å¤šè¯­è¨€æ”¯æŒ** - æ‰©å±•è¯­è¨€èƒ½åŠ›
3. **ä¸“ä¸šé—®ç­”** - æ„å»ºçŸ¥è¯†åº“RAGç³»ç»Ÿ
4. **å®‰å…¨å®¡è®¡** - é›†æˆé£æ§æ¨¡å‹

## æ³¨æ„äº‹é¡¹

- éµå®ˆæ¨¡å‹ä½¿ç”¨è®¸å¯åè®®
- ç”Ÿäº§ç¯å¢ƒæ³¨æ„APIå®‰å…¨
- å»ºè®®ä½¿ç”¨åç«¯æœåŠ¡ä»£ç†APIè°ƒç”¨
`;
}
